
!> \mainpage Numerical analysis main page
!>
!> Most of the functions for numerical analysis are in the \ref numa module.
!>
!> The source code is hosted on github:
!>
!> https://github.com/JeffIrwin/numerical-analysis
!>
!> This documentation is automatically generated by Doxygen.
!>

!===============================================================================

#include "panic.F90"

!> Main public-facing module for numerical analysis
module numa

	use numa__blarg
	use numa__core
	use numa__integrate
	use numa__interp
	use numa__linalg
	use numa__linprog
	use numa__utils

	implicit none

	! TODO:
	!
	! - this file is too long. it might be good to split it up roughly
	!   per-chapter, e.g. into interpolate.f90, (fft.f90,) integrate.f90, etc.
	!   * wip
	!   * linalg is started. lots of other stuff should move there too
	!   * exercises need split up too
	! - Add ci/cd testing with ifx.  There are a couple workarounds in here
	!   specifically for Intel, e.g. initialization of complex arrays
	! - Add more doxygen doc strings, maybe at least just a `brief` for each
	!   public fn.  See `lagrange_interpolator()` which has an example doc
	!   string

	interface lu_invmul
		! The built-in `matmul()` works on matrices and vectors similarly
		!
		! This is the subroutine version which modifies its args
		procedure :: lu_invmul_vec
		procedure :: lu_invmul_mat
	end interface lu_invmul

	interface lu_factor
		procedure :: lu_factor_c64
		procedure :: lu_factor_f64
	end interface lu_factor
	interface lu_solve
		procedure :: lu_solve_c64
		procedure :: lu_solve_f64
	end interface lu_solve
	interface lu_kernel
		procedure :: lu_kernel_c64
		procedure :: lu_kernel_f64
	end interface lu_kernel

	interface backsub
		procedure :: backsub_c64
		procedure :: backsub_f64
	end interface backsub

	interface invmul
		! This is the function version which returns the result
		procedure :: invmul_vec_c64
		!procedure :: invmul_mat_c64
		procedure :: invmul_vec_f64
		procedure :: invmul_mat_f64
	end interface invmul

	interface triu
		procedure :: triu_c64
		procedure :: triu_f64
	end interface triu

	interface qr_solve
		!procedure :: qr_solve_c64
		procedure :: qr_solve_f64
	end interface qr_solve
	interface qr_factor
		procedure :: qr_factor_c64
		procedure :: qr_factor_f64
	end interface qr_factor
	interface qr_get_q_expl
		procedure :: qr_get_q_expl_c64
		procedure :: qr_get_q_expl_f64
	end interface qr_get_q_expl

	interface qr_mul
		procedure :: qr_mul_mat_c64
		procedure :: qr_mul_mat_f64
		! Needs vec overloads
	end interface qr_mul

	interface qr_mul_transpose
		procedure :: qr_mul_transpose_vec_f64
		procedure :: qr_mul_transpose_mat_f64
		! Needs c64 overloads
	end interface qr_mul_transpose

contains

!===============================================================================

subroutine banded_factor(a, al, indx, nl, nu, iostat)
	! This is the factorization phase of banded_invmul(), with pivoting
	!
	! Compare the interface of lapack routines dgbtrf() (factor) and dgbtrs()
	! (solve) vs dgbsv() (combined factor-solve)

	use numa__utils

	! Reconsider the order of arguments -- maybe in(out) first and out last.  Or
	! perhaps it's better to leave as-is for consistency with banded_solve()
	! args
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable, intent(out) :: al(:,:)
	integer, allocatable, intent(out) :: indx(:)
	integer, intent(in) :: nl, nu
	integer, optional, intent(out) :: iostat

	!********
	character(len = :), allocatable :: msg
	double precision :: d, dum
	integer :: i, j, k, l, n, mm

	if (present(iostat)) iostat = 0

	!print *, "nl, nu = ", nl, nu

	n = size(a, 2)  ! *not* same as size 1
	mm = nl + 1 + nu

	if (nl + nu + 1 /= size(a, 1)) then
		msg = "bad size of matrix `a` in banded_factor()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if
	if (any(a(1: nl, 1) /= 0)) then
		msg = "`a(1:nl, 1)` is not 0 in tridiag_factor()"
		call PANIC(msg, present(iostat))
		iostat = 2
		return
	end if
	!if (any(a(mm-nu+1: mm, n) /= 0)) then
	if (any(a(nl+2: mm, n) /= 0)) then
		msg = "`a(nl+2: mm, n)` is not 0 in tridiag_factor()"
		call PANIC(msg, present(iostat))
		iostat = 3
		return
	end if

	! Left-shift the top nl rows by the number of zeros
	do i = 1, nl
		a(1: mm-nl+i-1, i) = a(1+nl-i+1: mm, i)
		a(mm - nl + i: mm, i) = 0
	end do
	d = 1  ! not used for anything, but it shows even vs odd row pivot permutations

	!print *, "a first loop = "
	!print "(5es18.6)", a

	allocate(indx(n))
	allocate(al(nl, n))
	l = nl
	do k = 1, n
		dum = a(1, k)
		i = k
		if (l < n) l = l + 1

		do j = k+1, l
			if (abs(a(1, j)) > abs(dum)) then
				dum = a(1, j)
				i = j
			end if
		end do

		indx(k) = i
		if (i /= k) then
			d = -d
			a(:, [i, k]) = a(:, [k, i])
		end if

		do i = k+1, l
			dum = a(1,i) / a(1,k)
			al(i-k, k) = dum
			a(1:mm-1, i) = a(2:mm, i) - dum * a(2:mm, k)
			a(mm, i) = 0
		end do
	end do
	!print *, "a = "
	!print "(5es18.6)", a
	!print *, "al = "
	!print "(2es18.6)", al

end subroutine banded_factor

!********

subroutine banded_solve(a, al, indx, nl, nu, bx)

	! This is the solving phase of banded_invmul()

	double precision, intent(in) :: a(:,:)
	double precision, intent(in) :: al(:,:)
	integer, intent(in) :: indx(:)

	double precision, intent(inout) :: bx(:)  ! could be extended to rank-2 for multiple RHS's

	integer, intent(in) :: nl, nu

	!********
	double precision :: dum
	integer :: i, j, k, l, n, mm

	!********
	! Solve stage

	n = size(a, 2)  ! *not* same as size 1
	mm = nl + 1 + nu

	l = nl
	do k = 1, n
		j = indx(k)
		if (j /= k) bx([j, k]) = bx([k, j])
		if (l < n) l = l + 1
		bx(k+1: l) = bx(k+1: l) - al(1: l-k, k) * bx(k)
	end do

	l = 1
	do i = n, 1, -1
		dum = bx(i) - dot_product(a(2:l, i), bx(i+1: l+i-1))
		bx(i) = dum / a(1, i)
		if (l < mm) l = l + 1
	end do

end subroutine banded_solve

!********

!> @brief  Solves a linear system `a*x == b` for `x` with a banded matrix `a`
!>
!> @details
!> Banded matrix `a` is packed into a mostly sparse rectangular array.  For
!> example, this data structure:
!>
!>     nl = 2  ! number of lower bands
!>     nu = 1  ! number of upper bands
!>     n  = 5  ! size of x
!>     allocate(a(nl+nu+1, n))
!>     a(:, 1) = [0, 0, 5, 2]
!>     a(:, 2) = [0, 3, 6, 2]
!>     a(:, 3) = [2, 3, 7, 2]
!>     a(:, 4) = [2, 3, 8, 2]
!>     a(:, 5) = [2, 3, 3, 0]
!>
!> represents this dense matrix in MATLAB/Scilab layout:
!>
!>     a = [
!>         5 2 0 0 0
!>         3 6 2 0 0
!>         2 3 7 2 0
!>         0 2 3 8 2
!>         0 0 2 3 3
!>     ]
!>
!> @param[in,out]  a   Banded matrix on input, factored on output
!> @param[in,out]  bx  RHS `b` on input, `x` on output
!> @param[in]      nl  Number of lower non-zero bands below diagonal
!> @param[in]      nu  Number of upper non-zero bands above diagonal
subroutine banded_invmul(a, bx, nl, nu)
	! Maybe should {a, nl, nu} be a struct?  One of the n*'s could be redundant

	double precision, intent(inout) :: a(:,:)
	double precision, intent(inout) :: bx(:)  ! could be extended to rank-2 for multiple RHS's
	integer, intent(in) :: nl, nu

	!********

	double precision, allocatable :: al(:,:)
	integer, allocatable :: indx(:)

	call banded_factor(a, al, indx, nl, nu)
	call banded_solve (a, al, indx, nl, nu, bx)

end subroutine banded_invmul

!===============================================================================

function invmul_vec_c64(a, b) result(x)
	! Solve the linear algebra problem for `x`:
	!
	!     a * x = b

	double complex, intent(in) :: a(:,:)
	double complex, intent(in) :: b(:)
	double complex, allocatable :: x(:)

	!********

	double complex, allocatable :: aa(:,:)

	integer :: i
	integer, allocatable :: pivot(:)

	x = b
	aa = a

	! Initialize pivot to identity
	pivot = [(i, i = 1, size(aa,1))]

	call lu_factor(aa, pivot)

	!print *, "pivot = ", pivot
	!print *, "lu_factor(aa) = "
	!!print "(5es18.6)", aa
	!print "(6es15.5)", transpose(aa)

	call lu_solve(aa, x, pivot)

end function invmul_vec_c64

subroutine lu_invmul_vec(a, bx)
	! Solve the linear algebra problem for `x`:
	!
	!     a * x = b

	double precision, intent(inout) :: a(:,:)
	double precision, intent(inout) :: bx(:)

	!********

	integer :: i
	integer, allocatable :: pivot(:)

	! Initialize pivot to identity
	pivot = [(i, i = 1, size(a,1))]

	call lu_factor(a, pivot)

	!print *, "pivot = ", pivot
	!print *, "lu_factor(a) = "
	!!print "(5es18.6)", a
	!print "(6es15.5)", transpose(a)

	call lu_solve(a, bx, pivot)

end subroutine lu_invmul_vec

!********

function invmul_vec_f64(a, b) result(x)
	double precision, intent(in)  :: a(:,:)
	double precision, intent(in)  :: b(:)
	double precision, allocatable :: x(:)
	!********
	double precision, allocatable :: aa(:,:)

	x = b
	aa = a
	call lu_invmul(aa, x)

end function invmul_vec_f64

function invmul_mat_f64(a, b) result(x)
	double precision, intent(in)  :: a(:,:)
	double precision, intent(in)  :: b(:,:)
	double precision, allocatable :: x(:,:)
	!********
	double precision, allocatable :: aa(:,:)

	x = b
	aa = a
	call lu_invmul(aa, x)

end function invmul_mat_f64

!********

subroutine lu_invmul_mat(a, bx)
	! Solve the linear algebra problem for `x`:
	!
	!     a * x = b

	double precision, intent(inout) :: a(:,:)
	double precision, intent(inout) :: bx(:,:)

	!********

	integer :: i, nrhs
	integer, allocatable :: pivot(:)

	! Initialize pivot to identity
	pivot = [(i, i = 1, size(a,1))]

	call lu_factor(a, pivot)

	!print *, "pivot = ", pivot
	!print *, "lu_factor(a) = "
	!!print "(5es18.6)", a
	!print "(6es15.5)", transpose(a)

	nrhs = size(bx, 2)
	do i = 1, nrhs
		call lu_solve(a, bx(:,i), pivot)
	end do

end subroutine lu_invmul_mat

!********

subroutine lu_factor_f64(a, pivot, allow_singular, iostat)

	!! Make pivoting optional (for comparison to other solvers)
	!logical, parameter :: DO_PIVOT = .false.

	use numa__utils
	double precision, intent(inout) :: a(:,:)
	integer, allocatable, intent(inout) :: pivot(:)
	integer, optional, intent(out) :: iostat
	logical, optional, intent(in) :: allow_singular

	!********

	character(len = :), allocatable :: msg
	integer :: i, j, k, n, max_index
	logical :: allow_singular_

	if (present(iostat)) iostat = 0

	allow_singular_ = .false.
	if (present(allow_singular)) allow_singular_ = allow_singular

	!print *, "pivot = ", pivot

	n = size(a, 1)

	if (size(a, 2) /= n) then
		msg = "matrix is not square in lu_factor_f64()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	if (.not. allocated(pivot)) then
		! Or we could just allocate and initialize (to identity perm) here
		!
		! Maybe this shouldn't be checked manually at all and we should just let
		! a stacktrace get issued, as with `a`
		msg = "pivot is not allocated in lu_factor_f64()"
		call PANIC(msg, present(iostat))
		iostat = 2
		return
	end if

	do i = 1, n
		! Find max value in column i
		max_index = i
		!if (DO_PIVOT) then
			do j = i+1, n
				if (abs(a(j,i)) > abs(a(i,i))) max_index = j
			end do
		!end if

		! Swap rows
		pivot([i, max_index]) = pivot([max_index, i])

		if (.not. allow_singular_ .and. a(pivot(i), i) == 0) then
			msg = "matrix is singular in lu_factor_f64()"
			call PANIC(msg, present(iostat))
			iostat = 3
			return
		end if

		do j = i+1, n
			a    (pivot(j), i) = &
				a(pivot(j), i) / &
				a(pivot(i), i)
			do k = i+1, n
				a    (pivot(j), k) = &
					a(pivot(j), k) - &
					a(pivot(j), i) * &
					a(pivot(i), k)
			end do
		end do

	end do

end subroutine lu_factor_f64

!********

subroutine lu_factor_c64(a, pivot, allow_singular, iostat)

	use numa__utils
	double complex, intent(inout) :: a(:,:)
	integer, allocatable, intent(inout) :: pivot(:)
	logical, optional, intent(in) :: allow_singular
	integer, optional, intent(out) :: iostat

	!********

	character(len = :), allocatable :: msg
	integer :: i, j, k, n, max_index
	logical :: allow_singular_

	if (present(iostat)) iostat = 0

	allow_singular_ = .false.
	if (present(allow_singular)) allow_singular_ = allow_singular

	!print *, "pivot = ", pivot

	n = size(a, 1)

	if (size(a, 2) /= n) then
		msg = "matrix is not square in lu_factor_c64()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	if (.not. allocated(pivot)) then
		! Or we could just allocate and initialize (to identity perm) here
		!
		! Maybe this shouldn't be checked manually at all and we should just let
		! a stacktrace get issued, as with `a`
		msg = "pivot is not allocated in lu_factor_c64()"
		call PANIC(msg, present(iostat))
		iostat = 2
		return
	end if

	do i = 1, n
		! Find max value in column i
		max_index = i
		do j = i+1, n
			if (abs(a(j,i)) > abs(a(i,i))) max_index = j
		end do

		! Swap rows
		pivot([i, max_index]) = pivot([max_index, i])

		if (.not. allow_singular_ .and. a(pivot(i), i) == 0) then
			msg = "matrix is singular in lu_factor_c64()"
			call PANIC(msg, present(iostat))
			iostat = 3
			return
		end if

		do j = i+1, n
			a    (pivot(j), i) = &
				a(pivot(j), i) / &
				a(pivot(i), i)
			do k = i+1, n
				a    (pivot(j), k) = &
					a(pivot(j), k) - &
					a(pivot(j), i) * &
					a(pivot(i), k)
			end do
		end do

	end do

end subroutine lu_factor_c64

!********

subroutine cholesky_factor(a, allow_singular, iostat)
	! Cholesky factorization is only possible for positive definite matrices
	! `a`!  There is no enforcement here

	use numa__utils
	double precision, intent(inout) :: a(:,:)
	logical, optional, intent(in) :: allow_singular
	integer, optional, intent(out) :: iostat

	!********

	character(len = :), allocatable :: msg
	double precision :: x, p
	integer :: i, j, k, n
	logical :: allow_singular_

	if (present(iostat)) iostat = 0

	allow_singular_ = .false.
	if (present(allow_singular)) allow_singular_ = allow_singular

	n = size(a, 1)

	if (size(a, 2) /= n) then
		msg = "matrix is not square in cholesky_factor()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	do i = 1, n
	do k = i, n
		x = a(i,k)
		do j = i-1, 1, -1
			x = x - a(k,j) * a(i,j)
		end do
		if (i == k) then
			if (x <= 0.d0 .and. .not. allow_singular_) then
				msg = "matrix is singular in cholesky_factor()"
				call PANIC(msg, present(iostat))
				iostat = 1
				return
			end if
			p = 1.d0 / sqrt(x)
		end if
		a(k,i) = x * p
	end do
	end do

end subroutine cholesky_factor

!********

subroutine hess(a, u)
	! Apply the Householder Hessenberg reduction to `a`
	!
	! Source:  https://dspace.mit.edu/bitstream/handle/1721.1/75282/18-335j-fall-2006/contents/lecture-notes/lec14.pdf
	use numa__blarg
	use numa__utils
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable, optional, intent(out) :: u(:,:)
	!********

	integer :: i, j, k, n
	double precision :: va
	double precision, allocatable :: v(:), vv(:,:)

	n = size(a,1)
	if (present(u)) allocate(vv(n, n-2))

	do k = 1, n-2

		v = a(k+1:, k)
		v(1) = v(1) + sign_(v(1)) * norm2(v)
		v = v / norm2(v)

		! Avoiding `v` temp array might be a little more work than worthwhile,
		! impossible if `u` is present
		do j = k, n
			va = 2 * dot_product(v, a(k+1:, j))
			a(k+1:, j) = a(k+1:, j) - va * v
		end do
		do i = 1, n
			va = 2 * dot_product(v, a(i, k+1:))
			a(i, k+1:) = a(i, k+1:) - va * v
		end do

		if (present(u)) vv(1: size(v), k) = v

	end do
	if (.not. present(u)) return

	u = eye(n)
	do k = n-2, 1, -1

		v = vv(1: n-k, k)
		do j = k+1, n
			va = 2 * dot_product(v, u(k+1:, j))
			u(k+1:, j) = u(k+1:, j) - va * v
		end do

	end do
	!print *, "u = "
	!print "(4es15.5)", u

end subroutine hess

!********

subroutine qr_factor_gram_schmidt(a, r)
	! Replace `a` with its QR factorization using modified Gram-Schmidt
	!
	! The Householder algorithm in `qr_factor()` is better because it is more
	! numerically stable

	double precision, intent(inout) :: a(:,:)
	double precision, allocatable, intent(out) :: r(:,:)
	!********

	double precision, allocatable :: ai(:)

	integer :: i, j, n

	n = size(a, 1)
	r = zeros(n, n)

	do i = 1, n

		ai = a(:,i)  ! save backup to get r later
		do j = 1, i-1

			a(:,i) = a(:,i) - a(:,j) * &
				dot_product(a(:,j), a(:,i)) / dot_product(a(:,j), a(:,j))

		end do
		a(:,i) = a(:,i) / norm2(a(:,i))

		r(i,i) = dot_product(a(:,i), ai)
		do j = i+1, n
			r(i,j) = dot_product(a(:,i), a(:,j))
		end do

	end do

end subroutine qr_factor_gram_schmidt

!********

subroutine qr_factor_f64(a, diag_, allow_rect, iostat)
	! Replace `a` with its QR factorization using Householder transformations
	use numa__utils
	double precision, intent(inout) :: a(:,:)

	double precision, allocatable, intent(out) :: diag_(:)
	logical, optional, intent(in) :: allow_rect
	integer, optional, intent(out) :: iostat

	!********

	character(len = :), allocatable :: msg
	double precision :: s, normx, u1, wa
	integer :: j, k, n
	logical :: allow_rect_

	allow_rect_ = .false.
	if (present(iostat)) iostat = 0
	if (present(allow_rect)) allow_rect_ = allow_rect

	n = min(size(a,1), size(a,2))

	allocate(diag_(n))
	diag_ = 0.d0

	if (.not. allow_rect_ .and. size(a, 1) /= size(a, 2)) then
		msg = "matrix is not square in qr_factor_f64()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	! Ref:  https://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf
	do j = 1, n

		normx = norm2(a(j:, j))
		if (normx <= 0) then
			msg = "matrix is singular in qr_factor_f64()"
			call PANIC(msg, present(iostat))
			iostat = 2
			return
		end if

		s = -sign_(a(j,j))
		u1 = a(j,j) - s * normx
		a(j+1:, j) = a(j+1:, j) / u1
		a(j,j) = s * normx
		diag_(j) = -s * u1 / normx

		do k = j+1, n
			wa = diag_(j) * (dot_product(a(j+1:, j), a(j+1:, k)) + a(j,k))
			a(j,k) = a(j,k) - wa
			a(j+1:, k) = a(j+1:, k) - a(j+1:, j) * wa
		end do

	end do
	!print *, "diag_ = "
	!print "(es15.5)", diag_

	! In the end, `R` is formed by zeroing appropriate elements of `a`
	!
	! And then `Q` can be expensively calculated as inv(r) * a (or some similar
	! transpose), or more efficiently using qr_get_q_expl()
	!
	! Results can be checked by verifying that q' * q == eye() or that a = q * r

end subroutine qr_factor_f64

function qr_mul_mat_f64(qr, diag_, x) result(qx)
	! Implicitly multiply Q * x with a previously computed QR factorization `qr`
	double precision, intent(in) :: qr(:,:), diag_(:), x(:,:)
	double precision, allocatable :: qx(:,:)
	!********
	double precision :: wq

	integer :: j, k, n

	!print *, "qr = "
	!print "(5es15.5)", qr

	n = min(size(qr,1), size(qr,2))
	qx = x  ! could make a subroutine version which replaces x instead

	do j = n, 1, -1
		do k = 1, size(qr, 2)
			wq = diag_(j) * (dot_product(qr(j+1:, j), qx(j+1:, k)) + qx(j,k))
			qx(j, k) = qx(j, k) - wq
			qx(j+1:, k) = qx(j+1:, k) - qr(j+1:, j) * wq
		end do
	end do

	!print *, "qx = "
	!print "(5es15.5)", qx

end function qr_mul_mat_f64

function qr_mul_transpose_mat_f64(qr, diag_, x) result(qx)
	! Implicitly multiply transpose(Q) * x with a previously computed QR factorization `qr`
	!
	! TODO: add c64 version and c64 test
	double precision, intent(in) :: qr(:,:), diag_(:), x(:,:)
	double precision, allocatable :: qx(:,:)
	!********
	double precision :: wq

	integer :: j, k, n

	!print *, "qr = "
	!print "(5es15.5)", qr

	n = min(size(qr,1), size(qr,2))
	qx = x  ! could make a subroutine version which replaces x instead

	! This loop order is the only difference from qr_mul()
	do j = 1, n
		do k = 1, size(qx, 2)
			wq = diag_(j) * (dot_product(qr(j+1:, j), qx(j+1:, k)) + qx(j,k))
			qx(j, k) = qx(j, k) - wq
			qx(j+1:, k) = qx(j+1:, k) - qr(j+1:, j) * wq
		end do
	end do
	qx = qx(1:n, :)  ! trim

	!print *, "qx = "
	!print "(5es15.5)", qx

end function qr_mul_transpose_mat_f64

function qr_mul_transpose_vec_f64(qr, diag_, x) result(qx)
	! Implicitly multiply transpose(Q) * x with a previously computed QR factorization `qr`
	!
	! TODO: add c64 version
	double precision, intent(in) :: qr(:,:), diag_(:), x(:)
	double precision, allocatable :: qx(:)
	!********
	double precision :: wq

	integer :: j, n

	!print *, "qr = "
	!print "(5es15.5)", qr

	n = min(size(qr,1), size(qr,2))
	qx = x  ! could make a subroutine version which replaces x instead

	! This loop order is the only difference from qr_mul()
	do j = 1, n
		wq = diag_(j) * (dot_product(qr(j+1:, j), qx(j+1:)) + qx(j))
		qx(j) = qx(j) - wq
		qx(j+1:) = qx(j+1:) - qr(j+1:, j) * wq
	end do
	qx = qx(1:n)  ! trim

	!print *, "qx = "
	!print "(5es15.5)", qx

end function qr_mul_transpose_vec_f64

!********

function qr_get_q_expl_f64(qr, diag_) result(q)
	! Explicitly get the unitary Q matrix from a previously QR-decomposed
	! matrix.  In most cases you will want to avoid using this fn and just
	! implicitly multiply something by Q instead using qr_mul()
	use numa__blarg
	use numa__utils
	double precision, intent(in) :: qr(:,:), diag_(:)
	double precision, allocatable :: q(:,:)

	q = qr_mul(qr, diag_, eye(size(qr,1)))

end function qr_get_q_expl_f64

function triu_f64(a) result(r)
	! Explicitly get R by zeroing lower triangle
	double precision, intent(in) :: a(:,:)
	double precision, allocatable :: r(:,:)
	!********
	integer :: i, n

	n = min(size(a,1), size(a,2))
	r = a(:n, :n)
	do i = 1, n
		r(i+1:, i) = 0
	end do

end function triu_f64

!********

subroutine qr_factor_c64(a, diag_, iostat)
	! Replace `a` with its QR factorization using Householder transformations
	use numa__blarg
	use numa__utils
	double complex, intent(inout) :: a(:,:)

	double complex, allocatable, intent(out) :: diag_(:)
	integer, optional, intent(out) :: iostat

	!********

	character(len = :), allocatable :: msg
	double complex :: wa
	integer :: j, k, n, io

	if (present(iostat)) iostat = 0

	n = size(a, 1)

	if (size(a, 2) /= n) then
		! This could have an allow_rect override like qr_factor_f64()
		msg = "matrix is not square in qr_factor_c64()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	allocate(diag_(n))
	diag_ = 0.d0

	! Ref:  https://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf
	do j = 1, n

		call house_c64(a(j,j), a(j+1:, j), diag_(j), io)
		if (io /= 0) then
			msg = "matrix is singular in qr_factor_c64()"
			call PANIC(msg, present(iostat))
			iostat = 2
			return
		end if

		do k = j+1, n
			! Note diag_ is conjugated here, unlike in qr_mul_c64()
			wa = conjg(diag_(j)) * (dot_product(a(j+1:, j), a(j+1:, k)) + a(j,k))
			a(j,k) = a(j,k) - wa
			a(j+1:, k) = a(j+1:, k) - a(j+1:, j) * wa
		end do

	end do
	!print *, "diag_ = "
	!print "(es15.5)", diag_

end subroutine qr_factor_c64

function qr_mul_mat_c64(qr, diag_, x) result(qx)
	! Implicitly multiply Q * x with a previously computed QR factorization `qr`
	double complex, intent(in) :: qr(:,:), diag_(:), x(:,:)
	double complex, allocatable :: qx(:,:)
	!********
	double complex :: wq
	!double complex, allocatable :: w(:)
	integer :: j, k, n

	!print *, "qr = "
	!print "(5es15.5)", qr

	n = size(qr, 1)
	qx = x

	! To multiply by transpose(Q) instead, just loop from 1 up to n instead
	do j = n, 1, -1
		! Note that diag_ is *not* conjugated here, unlike in qr_factor_c64()
		do k = 1, n
			wq = diag_(j) * (dot_product(qr(j+1:, j), qx(j+1:, k)) + qx(j,k))
			qx(j, k) = qx(j, k) - wq
			qx(j+1:, k) = qx(j+1:, k) - qr(j+1:, j) * wq
		end do
	end do
	!print *, "qx = "
	!print "(5es15.5)", qx

end function qr_mul_mat_c64

!********

function qr_get_q_expl_c64(qr, diag_) result(q)
	! Explicitly get the unitary Q matrix from a previously QR-decomposed
	! matrix.  In most cases you will want to avoid using this fn and just
	! implicitly multiply something by Q instead using qr_mul()
	use numa__blarg
	use numa__utils
	double complex, intent(in) :: qr(:,:), diag_(:)
	double complex, allocatable :: q(:,:)

	q = qr_mul(qr, diag_, dcmplx(eye(size(qr,1))))

end function qr_get_q_expl_c64

function triu_c64(a) result(r)
	! Explicitly get R (U) by zeroing lower triangle
	double complex, intent(in) :: a(:,:)
	double complex, allocatable :: r(:,:)
	!********
	integer :: i

	r = a
	do i = 1, size(a, 1)
		r(i+1:, i) = 0
	end do

end function triu_c64

!********

subroutine cholesky_solve(a, bx)

	double precision, intent(in) :: a(:,:)
	double precision, intent(inout) :: bx(:)

	integer :: i, j, n

	n = size(a, 1)
	!print *, "bx init = ", bx

	! This is the same as lu_solve(), except:
	! - The pivot is the identity
	! - One of the `a` terms is transposed, because U == transpose(L)
	! - Forward substitution has an extra division step because U has non-zero diagonals

	! Forward substitution
	do i = 1, n
		do j = 1, i-1
			bx(i) = bx(i) - a(i, j) * bx(j)
		end do
		bx(i) = bx(i) / a(i, i)
	end do
	!print *, "bx forward = ", bx

	! Back substitution
	do i = n, 1, -1
		do j = i+1, n
			! Note `a` indices are transposed because its symmetric
			bx(i) = bx(i) - a(j, i) * bx(j)
		end do
		bx(i) = bx(i) / a (i, i)
	end do
	!print *, "bx back = ", bx

	! No pivoting for Cholesky

end subroutine cholesky_solve

!********

subroutine lu_solve_c64(a, bx, pivot)

	double complex, intent(in) :: a(:,:)
	double complex, intent(inout) :: bx(:)
	integer, intent(in) :: pivot(:)

	integer :: i, j, n

	!print *, "pivot lu_solve_c64 = ", pivot

	n = size(a, 1)
	!print *, "bx init = ", bx

	! Forward substitution
	do i = 1, n
		do j = 1, i-1
			bx    (pivot(i)) = &
				bx(pivot(i)) - &
				a (pivot(i), j) * &
				bx(pivot(j))
		end do
	end do
	!print *, "bx forward = ", bx

	call backsub(a, bx, pivot)

	! Unpivot
	bx = bx(pivot)
	!print *, "bx unpivot = ", bx

end subroutine lu_solve_c64

!********

subroutine lu_solve_f64(a, bx, pivot)

	double precision, intent(in) :: a(:,:)
	double precision, intent(inout) :: bx(:)
	integer, intent(in) :: pivot(:)

	integer :: i, j, n

	!print *, "pivot lu_solve_f64 = ", pivot

	n = size(a, 1)
	!print *, "bx init = ", bx

	! Forward substitution
	do i = 1, n
		do j = 1, i-1
			bx    (pivot(i)) = &
				bx(pivot(i)) - &
				a (pivot(i), j) * &
				bx(pivot(j))
		end do
	end do
	!print *, "bx forward = ", bx

	call backsub(a, bx, pivot)

	! Unpivot
	bx = bx(pivot)
	!print *, "bx unpivot = ", bx

end subroutine lu_solve_f64

!===============================================================================

function inv(a)
	! Return the inverse of matrix `a` without modifying `a`
	double precision, allocatable, intent(in) :: a(:,:)
	double precision, allocatable :: inv(:,:)

	!double precision, allocatable :: copy_(:,:)

	!! Use LU decomposition
	!copy_ = a
	!inv = eye(size(a,1))
	!call invmul(copy_, inv)

	! Use Gauss-Jordan.  I suspect it does less copying than my LU inverse
	! implementation.  It's around 40% faster, although both methods are O(n**3)
	inv = a
	call gauss_jordan(inv)

end function inv

!===============================================================================

subroutine invert(a)
	! Replace `a` with its inverse
	double precision, allocatable, intent(inout) :: a(:,:)
	!double precision, allocatable :: copy_(:,:)

	!********
	! Use Gauss-Jordan
	call gauss_jordan(a)

	!********
	! Use LU

	!! One move and one copy
	!call move_alloc(a, copy_)
	!a = eye(size(copy_, 1))
	!call invmul(copy_, a)

	!!! Two copies
	!!copy_ = a
	!!a = eye(size(a,1))
	!!call invmul(copy_, a)

	!!! Also two copies
	!!copy_ = eye(size(a,1))
	!!call invmul(a, copy_)
	!!a = copy_

	!!! Break tests
	!!a(1,1) = 1.01d0 * a(1,1)

end subroutine invert

!===============================================================================

subroutine gauss_jordan(a, iostat)
	! Use the Gauss-Jordan method to replace matrix `a` with its inverse
	use numa__utils
	double precision, allocatable, intent(inout) :: a(:,:)
	integer, optional, intent(out) :: iostat

	!********

	character(len = :), allocatable :: msg
	double precision :: max_, hr
	integer, allocatable :: p(:)
	integer :: i, j, k, n, r, r1(1)

	if (present(iostat)) iostat = 0

	n = size(a, 1)
	!print *, "n = ", n
	p = [(i, i = 1, n)]  ! pivot

	if (size(a, 2) /= n) then
		msg = "matrix is not square in gauss_jordan()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	do j = 1, n

		if (j < n) then
			r1 = maxloc(abs(a(j+1: n, j))) + j
		else
			r1 = n
		end if

		!print *, "a : = ", a(j+1: n, j)
		!print *, "maxloc = ", maxloc(abs(a(j+1: n, j)))
		!print *, "r1 = ", r1
		!print *, ""

		r = r1(1)
		max_ = abs(a(r, j))
		if (max_ <= 0) then
			msg = "matrix is singular in gauss_jordan()"
			call PANIC(msg, present(iostat))
			iostat = 2
			return
		end if

		if (r > j) then
			! Swap rows
			a([j, r], :) = a([r, j], :)
			p([j, r]) = p([r, j])
		end if

		! Transform
		hr = 1.d0 / a(j,j)
		a(:,j) = a(:,j) * hr
		a(j,j) = hr
		do k = 1, n
			if (k == j) cycle
			do i = 1, n
				if (i == j) cycle

				a(i,k) = a(i,k) - a(i,j) * a(j,k)
			end do
			a(j,k) = -hr * a(j,k)
		end do

	end do

	! Swap columns
	a(:,p) = a

	!print *, "In Gauss-Jordan:"
	!print *, "a = "
	!print "(5es18.6)", a

end subroutine gauss_jordan

!===============================================================================

function eig_basic_qr(a, iters, iostat) result(eigvals)
	! Get the real eigenvalues of `a` using `iters` iterations of the basic QR
	! algorithm.  Many iterations may be required for good convergence with
	! large sized `a`
	!
	! The matrix `a` is modified in the process by QR decomposition
	!
	! This only supports real eigenvalues.  The same algorithm could be adapted
	! for complex eigenvalues:
	!
	!     https://math.stackexchange.com/a/3072781/232771
	!
	! The basic idea is that `a` converges to a "quasi-triangular" real matrix
	! in this algorithm.  Where the off-triangle approaches 0, we have real
	! eigenvalues.  Where there is a non-zero in the off-diagonal, we have a
	! complex conjugate pair of eigenvalues, which could be computed as the same
	! eigenvalue of its 2x2 sub-matrix block
	!
	! A better algorithm would also take a tolerance rather than a fixed number
	! of iterations
	!
	! But it's not a good idea to waste time on such improvements for as slow an
	! algorithm as basic QR.  Rather, wait and do the good work on something
	! better like Hessenberg QR, or better yet, a shifting algorithm

	use numa__utils
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable :: eigvals(:)
	integer, intent(in) :: iters
	integer, optional, intent(out) :: iostat
	!********

	character(len = :), allocatable :: msg
	double precision, allocatable :: diag_(:), q(:,:)
	integer :: i, io

	if (present(iostat)) iostat = 0

	do i = 1, iters
		call qr_factor(a, diag_, iostat = io)
		if (io /= 0) then
			msg = "qr_factor() failed in eig_basic_qr()"
			call PANIC(msg, present(iostat))
			iostat = 1
			return
		end if

		! Could also do a = transpose(qr_mul_transpose(), transpose(r)),
		! but two transposes seems expensive
		q = qr_get_q_expl(a, diag_)
		a = matmul_triu_ge(a, q)
	end do
	!print *, "a = "
	!print "(4es15.5)", a

	eigvals = sorted(diag(a))
	!print *, "eigvals = ", eigvals

end function eig_basic_qr

!===============================================================================

function matmul_triu_ge(upper, ge, iostat) result(res)
	! Multiply an upper-triangular matrix by a general dense matrix
	use numa__utils
	double precision, intent(in) :: upper(:,:), ge(:,:)
	double precision, allocatable :: res(:,:)
	integer, optional, intent(out) :: iostat
	!********

	character(len = :), allocatable :: msg
	integer :: i, j, k, ni, nj, nk

	if (present(iostat)) iostat = 0

	ni = size(upper, 1)
	nj = size(upper, 2)
	nk = size(ge, 2)

	if (nj /= size(ge, 1)) then
		msg = "inner dimensions do not agree in matmul_triu_ge()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if

	res = zeros(ni, nk)
	do k = 1, nk
	do j = 1, nj
	do i = 1, j  ! this loop is half the extent of general matmul

		! Is it possible to overwrite the result to upper?  I don't see how,
		! because it appears on both the LHS and RHS of this expression
		res(i, k) = res(i, k) + upper(i, j) * ge(j, k)

	end do
	end do
	end do

end function matmul_triu_ge

!===============================================================================

function eig_hess_qr(a, iters, eigvecs) result(eigvals)
	! Get the real eigenvalues of `a` using `iters` iterations of the Hessenberg
	! QR algorithm

	use numa__blarg
	use numa__utils
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable :: eigvals(:)
	integer, intent(in) :: iters
	double precision, optional, allocatable, intent(out) :: eigvecs(:,:)
	!********

	double precision :: h1, h2, rad, givens(2,2)
	double precision, allocatable :: c(:), s(:), &
		pq(:,:), r(:,:)
	integer :: i, k, n

	n = size(a, 1)
	allocate(c(n-1), s(n-1))

	! The matrix `pq` is the product of Q from each step.  Unlike basic QR, we
	! can't initialize pq to eye here.  Instead, we need an initial
	! transformation from the Hessenberg reduction
	call hess(a, pq)

	do i = 1, iters

		do k = 1, n-1
			h1 = a(k, k)
			h2 = a(k+1, k)

			rad = norm2([h1, h2])
			!print *, "rad = ", rad
			c(k) =  h1 / rad
			s(k) = -h2 / rad
			givens(1,:) = [c(k), -s(k)]
			givens(2,:) = [s(k),  c(k)]

			! Ref:  https://people.inf.ethz.ch/arbenz/ewp/Lnotes/chapter4.pdf
			a(k:k+1, k:) = matmul(givens, a(k:k+1, k:))

		end do
		!print *, "r = "
		!print "(4es15.5)", a

		!! If you stop here, `a` has been overwritten with `r` from its QR
		!! factorization.  You could also compute Q by applying the matmuls in the
		!! loop above to an initial identity matrix, but we don't need Q explicitly
		!! for a Hessenberg QR step
		!stop

		! The rest of the Hessenberg QR step is not part of the QR factorization,
		! rather, it overwrites `a` with R * Q

		! Apply the Givens rotations from the right
		do k = 1, n-1
			givens(1,:) = [ c(k), s(k)]  ! note this is transposed compared to above
			givens(2,:) = [-s(k), c(k)]
			a(1: k+1, k: k+1) = matmul(a(1: k+1, k: k+1), givens)

			if (.not. present(eigvecs)) cycle

			! Update Q product
			pq(:, k:k+1) = matmul(pq(:, k:k+1), givens)

		end do

	end do
	!print *, "a = "
	!print "(4es15.5)", a

	! Don't sort the eigvals, because that will break the ordering of eigvecs
	!eigvals = sorted(diag(a))

	eigvals = diag(a)

	if (.not. present(eigvecs)) return
	!********

	r = triu(a)
	!print *, "r = "
	!print "(4es15.5)", r

	! In order to get the eigenvectors of `a`, we first have to get the
	! eigenvectors of `r` and then transform them by `pq`
	!
	! Ref:  https://math.stackexchange.com/a/3947396/232771
	!
	! Especially the linked code:  https://gist.github.com/uranix/2b4bb821a0e3ffc4531bec547ea67727

	! Find the eigenvectors of `r`
	eigvecs = eye(n)
	do i = 2, n
		! scalar * eye could be optimized here to skip zeros
		eigvecs(1: i-1, i) = invmul(r(i,i) * eye(i-1) - r(:i-1, :i-1), r(:i-1, i))
	end do
	!print *, "R eigvecs = "
	!print "(4es15.5)", eigvecs

	eigvecs = matmul(pq, eigvecs)
	!print *, "eigvecs hess qr = "
	!print "(4es15.5)", eigvecs

	!print *, "a * w / w ="
	!print "(4es15.5)", matmul(a0, eigvecs) / eigvecs

end function eig_hess_qr

!===============================================================================

function house(x, iostat) result(pp)
	! Return the Householder reflector `pp` such that pp * x == [1, 0, 0, ...]
	!
	! Could just return `v` like house_c64(), but this fn is only used for 3x3
	! matrices, whereas house_c64() runs on arbitrarily large matrices for QR
	! factoring

	use numa__blarg
	use numa__utils
	double precision, intent(in) :: x(:)
	double precision, allocatable :: pp(:,:)
	integer, optional, intent(out) :: iostat
	!********

	character(len = :), allocatable :: msg
	double precision :: alpha, normv
	double precision, allocatable :: v(:)
	integer :: n

	if (present(iostat)) iostat = 0

	n = size(x)

	alpha = -sign_(x(1)) * norm2(x)
	v = x
	v(1) = v(1) - alpha

	normv = norm2(v)
	if (normv <= 0) then
		v = v * 1.d50
		normv = norm2(v)
		!print *, "normv = ", normv
		!print *, "v/normv = ", v / normv

		pp = eye(n)
		!print *, "v = ", v
		msg = "vector is singular in house()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if
	v = v / normv

	pp = eye(n) - 2.d0 * outer_product(v, v)

	!print *, "in house():"
	!print *, "x = ", x
	!print *, "pp = "
	!print "(3es15.5)", pp
	!print *, "pp * x = ", matmul(pp, x)

end function house

!===============================================================================

function eig_lapack(aa, eigvecs, iostat) result(eigvals)
	! Get the eigenvalues of `aa` using the Francis double step QR algorithm,
	! using LAPACK's dlahqr() routine (but still my home-made hess() routine)

	use numa__blarg
	use numa__dlahqr
	use numa__utils
	double precision, intent(inout) :: aa(:,:)
	double complex, allocatable :: eigvals(:)
	double complex, optional, allocatable, intent(out) :: eigvecs(:,:)
	integer, optional, intent(out) :: iostat
	!********

	character(len = :), allocatable :: msg
	double complex, allocatable :: ca(:,:), cq(:,:)
	double precision, parameter :: eps = 1.d-10
	double precision, allocatable :: pq(:,:)
	integer :: i, n

	if (present(iostat)) iostat = 0

	n = size(aa, 1)

	if (present(eigvecs)) then
		! The matrix `pq` is the product of Q from each step.  Unlike basic QR, we
		! can't initialize pq to eye here.  Instead, we need an initial
		! transformation from the Hessenberg reduction
		call hess(aa, pq)
	else
		call hess(aa)
	end if
	!print *, "aa = "
	!print "("//to_str(n)//"es19.9)", aa

	block
		double precision, allocatable :: wr(:), wi(:)
		integer :: ilo, ihi, ldh, iloz, ihiz, ldz, info
		logical :: wantt, wantz

		! Set indices to factorize all of `aa`, not just a slice
		ilo = 1
		ihi = n
		ldh = n
		iloz = 1
		ihiz = n
		ldz = n

		! Eigval real/imag components
		allocate(wr(n), wi(n))

		if (present(eigvecs)) then
			wantt = .true.  ! want full schur form, not just eigvals
			wantz = .true.
		else
			! Intel requires allocation of `pq` for dlahqr().  For GNU it
			! doesn't matter
			allocate(pq(0,0))
			wantt = .false.
			wantz = .false.
		end if

		call dlahqr(wantt, wantz, n, ilo, ihi, aa, ldh, wr, wi, &
			iloz, ihiz, pq, ldz, info)
		if (info /= 0) then
			msg = "dlahqr() failed in eig_lapack()"
			call PANIC(msg, present(iostat))
			iostat = 1
			return
		end if

		! Copy eigvals out
		eigvals = dcmplx(wr, wi)

	end block

	!print *, "aa = "
	!print "("//to_str(n)//"es16.6)", aa
	!print *, "pq = "
	!print "("//to_str(n)//"es16.6)", pq

	if (.not. present(eigvecs)) return

	! Zero the remaining below-diagonal non-zeros
	call real_schur_to_complex(aa, pq, ca, cq, eps)

	! No eigval swapping happens with LAPACK
	!eigvals = diag(ca)

	!print *, "ca = "
	!print "("//to_str(2*n)//"es19.9)", ca

	! Find the eigenvectors of triangular `ca`
	eigvecs = eye(n)
	do i = 2, n
		eigvecs(1: i-1, i) = invmul(ca(i,i) * eye(i-1) - ca(:i-1, :i-1) , ca(:i-1, i))
	end do
	!print *, "R eigvecs = "
	!print "("//to_str(n)//"es19.9)", eigvecs

	eigvecs = matmul(cq, eigvecs)

end function eig_lapack

!===============================================================================

function eig_francis_qr(aa, eigvecs, iostat) result(eigvals)
	! Get the eigenvalues of `aa` using the Francis double step QR algorithm.
	! Use eig_lapack() instead because it's much more robust
	use numa__blarg
	use numa__utils
	double precision, intent(inout) :: aa(:,:)
	double complex, allocatable :: eigvals(:)
	double complex, optional, allocatable, intent(out) :: eigvecs(:,:)
	integer, optional, intent(out) :: iostat
	!********

	character(len = :), allocatable :: msg

	double complex :: l1, l2
	double complex, allocatable :: ca(:,:), cq(:,:)

	! I still have doubts about robustness here because this tolerance is
	! extremely sensitive
	double precision, parameter :: eps = 1.d-10  ! should eps and iters be args?

	double precision :: rad, s, tr, x, y, z, p2(2,2), p3(3,3), ck, sk, &
		a, b, c, d, det_, v(3), aii, aij, aji, ajj, a11, a12, a21, a22, a32
	double precision, allocatable :: pq(:,:)

	integer, parameter :: iters = 100
	integer :: i, i1, k, n, j, k1, iter, io

	logical, allocatable :: is_real(:)

	if (present(iostat)) iostat = 0

	n = size(aa, 1)

	if (present(eigvecs)) then
		! The matrix `pq` is the product of Q from each step.  Unlike basic QR, we
		! can't initialize pq to eye here.  Instead, we need an initial
		! transformation from the Hessenberg reduction
		call hess(aa, pq)
	else
		call hess(aa)
	end if

	!print *, "aa = "
	!print "("//to_str(n)//"es19.9)", aa

	i = n  ! i indicates the active matrix size
	iter = 0

	! LAPACK has lots of logic to scale to avoid over/under flow which is
	! skipped here and thus not robust

	do while (i > 2)
		iter = iter + 1
		if (iter > iters) then
			msg = "convergence failed in eig_francis_qr()"
			call PANIC(msg, present(iostat))
			iostat = 1
			return
		end if
		!print *, "i = ", i

		j = i - 1
		aii = aa(i,i)
		aij = aa(i,j)
		aji = aa(j,i)
		ajj = aa(j,j)

		tr = (aii + ajj) / 1          ! trace
		det_ = ajj * aii - aji * aij  ! determinant

		! Compute first 3 elements of first column of M

		a11 = aa(1,1)
		a21 = aa(2,1)
		a12 = aa(1,2)
		a22 = aa(2,2)
		a32 = aa(3,2)

		x = a11**2 + a12 * a21 - tr * a11 + det_
		y = a21 * (a11 + a22 - tr)
		z = a21 * a32

		x = x
		y = y
		z = z

		do k = 0, i-3

			! Determine the Householder reflector `p3`.  Using a scalar `s`
			! here, and for the Givens rotation below, effectively aids
			! convergence for n >~ 40
			v = [x, y, z]
			s = sum(abs(v))
			v = v / s
			p3 = house(v, io)

			if (io /= 0) then
				!print *, "x, y, z = ", x, y, z
				msg = "house() failed in eig_francis_qr()"
				call PANIC(msg, present(iostat))
				iostat = 2
				return
			end if
			!print *, "p3 = "
			!print "(3es15.5)", p3

			k1 = max(1, k)
			aa(k+1: k+3, k1:) = matmul(p3, aa(k+1: k+3, k1:))

			k1 = min(k+4, i)
			aa(:k1, k+1: k+3) = matmul(aa(:k1, k+1: k+3), p3)

			if (present(eigvecs)) then
				pq(:, k+1: k+3) = matmul(pq(:, k+1: k+3), p3)
			end if

			x = aa(k+2, k+1)
			y = aa(k+3, k+1)
			if (k < i-3) then
				z = aa(k+4, k+1)
			end if

		end do

		! Determine the 2D Givens rotation `p2`

		s = abs(x) + abs(y)
		if (s <= 0) then
			!print *, "x, y = ", x, y
			msg = "matrix is singular in eig_francis_qr()"
			call PANIC(msg, present(iostat))
			iostat = 3
			return
		end if
		x = x / s
		y = y / s

		rad = norm2([x, y])
		ck =  x / rad
		sk = -y / rad
		p2(1,:) = [ck, -sk]
		p2(2,:) = [sk,  ck]

		aa(j:i, i-2:) = matmul(p2, aa(j:i, i-2:))
		aa(:i, i-1:i) = matmul(aa(:i, i-1:i), transpose(p2))

		if (present(eigvecs)) then
			pq(:, i-1:i) = matmul(pq(:, i-1:i), transpose(p2))
		end if

		! Check for convergence

		!print *, "aa(i,j)     = ", aa(i,j)
		!print *, "aa(i-1,j-1) = ", aa(i-1,j-1)

		if (abs(aa(i,j)) < eps * (abs(aa(j,j)) + abs(aa(i,i)))) then
			!print *, "i -= 1"
			aa(i,j) = 0.d0
			i = i - 1
			iter = 0
		else if (abs(aa(i-1, j-1)) < eps * (abs(aa(j-1, j-1)) + abs(aa(j,j)))) then
			!print *, "i -= 2"
			aa(i-1, j-1) = 0.d0
			i = i - 2
			iter = 0
		end if

	end do
	!print *, "aa = "
	!print "("//to_str(n)//"es19.9)", aa
	!print *, "pq = "
	!print "("//to_str(n)//"es19.9)", pq

	! Process 2x2 block along diagonal and get their eigenvalues.  Some
	! may be real, some may be complex
	allocate(is_real(n))
	is_real = .true.
	allocate(eigvals(n))
	do i = 1, n-1
		i1 = i + 1

		! 2x2 block around diagonal
		a = aa(i , i )
		b = aa(i1, i )
		c = aa(i , i1)
		d = aa(i1, i1)

		if (abs(b) <= eps * (abs(a) + abs(d))) cycle

		tr = a + d         ! trace
		det_ = a*d - b*c  ! determinant

		! Eigenvalues of 2x2 block
		!
		! Source:  https://people.math.harvard.edu/~knill/teaching/math21b2004/exhibits/2dmatrices/index.html
		l1 = tr/2 + sqrt(dcmplx(tr**2/4 - det_))
		l2 = tr/2 - sqrt(dcmplx(tr**2/4 - det_))

		!print *, "b  = ", b
		!print *, "l1 = ", l1
		!print *, "l2 = ", l2
		!print *, ""

		is_real(i ) = .false.
		is_real(i1) = .false.

		eigvals(i ) = l1
		eigvals(i1) = l2

	end do

	! Second pass: collect the real eigenvalues not saved in the first pass
	do i = 1, n
		if (.not. is_real(i)) cycle
		eigvals(i) = aa(i,i)
	end do

	!!print *, "eigvals sorted = ", sorted(eigvals)
	!print *, "eigvals = ", eigvals

	!********
	if (.not. present(eigvecs)) return

	! Zero the remaining below-diagonal non-zeros
	call real_schur_to_complex(aa, pq, ca, cq, eps)

	! Some of the eigenvalues get swapped around in real_schur_to_complex()
	eigvals = diag(ca)

	!print *, "ca = "
	!print "("//to_str(2*n)//"es19.9)", ca

	! Find the eigenvectors of triangular `ca`
	eigvecs = eye(n)
	do i = 2, n
		! Looking at LAPACK, it has a special-purpose quasi-triangular solver
		! for this problem.  There are cases for 1x1 blocks, 2x2 blocks, and
		! real or complex eigenvectors, with all complex numbers encoded as
		! pairs of reals, without explicitly doing rsf2csf:
		!
		!     https://netlib.org/lapack/explore-html/d2/d98/group__trevc3_gaee05b7252c5a3b2b935d5a4a6101033d.html
		!
		eigvecs(1: i-1, i) = invmul(ca(i,i) * eye(i-1) - ca(:i-1, :i-1) , ca(:i-1, i))
	end do
	!print *, "R eigvecs = "
	!print "("//to_str(n)//"es19.9)", eigvecs

	eigvecs = matmul(cq, eigvecs)

	!print *, "eigvecs francis qr = "
	!print "("//to_str(n)//"es19.9)", eigvecs

end function eig_francis_qr

!===============================================================================

subroutine real_schur_to_complex(r, q, cr, cq, eps)
	! Convert real Schur form [r, q] to complex Schur form [cr, cq].  Compare
	! the MATLAB and scipy functions rsf2csf()
	!
	! Matrix `r` is quasi-triangular and `q` is unitary
	use numa__blarg
	use numa__utils
	double precision, intent(in) :: r(:,:), q(:,:)
	double complex, allocatable, intent(out) :: cr(:,:), cq(:,:)
	double precision, intent(in) :: eps
	!********

	double complex :: mu(2), cc, sc, g(2,2)

	double precision :: a, b, c, d, t, det_, rad

	integer :: i

	! Cast to complex
	cr = r
	cq = q

	do i = 2, size(r, 1)
		! Source:
		!
		!     https://github.com/scipy/scipy/blob/3fe8b5088d1b63e7557d26314cf5f40851f46a45/scipy/linalg/_decomp_schur.py#L329

		if (abs(cr(i, i-1)) <= eps * (abs(cr(i-1, i-1)) + abs(cr(i,i)))) then
			cr(i, i-1) = 0
			cycle
		end if

		!print *, "Zeroing at i = ", i
		!print *, "cr(i, i-1) = ", cr(i, i-1)

		! 2x2 block around diagonal
		a = dble(cr(i-1, i-1))
		b = dble(cr(i, i-1))
		c = dble(cr(i-1, i))
		d = dble(cr(i, i))

		t = a + d         ! trace
		det_ = a*d - b*c  ! determinant

		! Eigenvalues of 2x2 block
		mu(1) = t/2 + sqrt(dcmplx(t**2/4 - det_))
		mu(2) = t/2 - sqrt(dcmplx(t**2/4 - det_))
		!print *, "mu = ", mu

		mu(1) = mu(1) - cr(i,i)

		! Maybe this could work as a replacement for dlanv2(), but cc and sc are
		! complex, not real
		rad = norm2c([mu(1), cr(i, i-1)])
		cc = mu(1) / rad
		sc = cr(i, i-1) / rad

		g(1,:) = [conjg(cc), sc]
		g(2,:) = [-sc, cc]

		cr(i-1:i, i-1:) = matmul(g, cr(i-1:i, i-1:))
		cr(:i, i-1:i)   = matmul(cr(:i, i-1:i), transpose(conjg(g)))
		cq(: , i-1:i)   = matmul(cq(: , i-1:i), transpose(conjg(g)))

		cr(i, i-1) = 0

		!print *, "cr = "
		!print "("//to_str(2*n)//"es19.9)", cr
		!print *, ""

	end do

end subroutine real_schur_to_complex

!===============================================================================

function lu_kernel_f64(a) result(kernel)
	! Find the kernel or null-space of `a` using LU decomposition.  This only
	! returns 1 vector of the kernel, not the whole kernel basis
	use numa__utils
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable :: kernel(:)

	integer :: i, n
	integer, allocatable :: pivot(:)

	n = size(a, 1)
	kernel = zeros(n)

	! The kernel of `a` is the same as `u`

	pivot = [(i, i = 1, size(a,1))]
	call lu_factor(a, pivot, allow_singular = .true.)

	! Partial backsub
	kernel(n) = 1.d0
	do i = n-1, 1, -1
		kernel(i) = &
			-dot_product(kernel(i+1:), a(pivot(i), i+1:n)) / a(pivot(i),i)
	end do

end function lu_kernel_f64

!===============================================================================

function lu_kernel_c64(a) result(kernel)
	! Find the kernel or null-space of `a` using LU decomposition
	use numa__utils
	double complex, intent(inout) :: a(:,:)
	double complex, allocatable :: kernel(:)

	integer :: i, n
	integer, allocatable :: pivot(:)

	n = size(a, 1)
	kernel = zeros(n)

	! The kernel of `a` is the same as `u`

	pivot = [(i, i = 1, size(a,1))]
	call lu_factor(a, pivot, allow_singular = .true.)

	! Partial backsub
	kernel(n) = 1.d0
	do i = n-1, 1, -1
		kernel(i) = &
			-dot_product(conjg(kernel(i+1:)), a(pivot(i), i+1:n)) / a(pivot(i), i)
	end do

end function lu_kernel_c64

!===============================================================================

function eig_hess_qr_kernel(a, iters, eigvecs) result(eigvals)
	! Get the real eigenvalues of `a` using `iters` iterations of the Hessenberg
	! QR algorithm
	!
	! To get the eigenvectors, find the kernel (null-space) of A-lambda*I for
	! each eigenvalue lambda

	use numa__utils, only:  sorted
	double precision, intent(inout) :: a(:,:)
	double precision, allocatable :: eigvals(:)
	integer, intent(in) :: iters
	double precision, optional, allocatable, intent(out) :: eigvecs(:,:)
	!********

	double precision :: h1, h2, rad, givens(2,2), eigval
	double precision, allocatable :: c(:), s(:), a0(:,:), &
		eigvec(:)
	integer :: i, j, k, n

	a0 = a

	n = size(a, 1)
	allocate(c(n-1), s(n-1))

	call hess(a)

	do i = 1, iters

		do k = 1, n-1
			h1 = a(k, k)
			h2 = a(k+1, k)

			rad = norm2([h1, h2])
			!print *, "rad = ", rad
			c(k) =  h1 / rad
			s(k) = -h2 / rad
			givens(1,:) = [c(k), -s(k)]
			givens(2,:) = [s(k),  c(k)]

			! Ref:  https://people.inf.ethz.ch/arbenz/ewp/Lnotes/chapter4.pdf
			a(k:k+1, k:) = matmul(givens, a(k:k+1, k:))

		end do
		!print *, "r = "
		!print "(4es15.5)", a

		!! If you stop here, `a` has been overwritten with `r` from its QR
		!! factorization.  You could also compute Q by applying the matmuls in the
		!! loop above to an initial identity matrix, but we don't need Q explicitly
		!! for a Hessenberg QR step
		!stop

		! The rest of the Hessenberg QR step is not part of the QR factorization,
		! rather, it overwrites `a` with R * Q

		! Apply the Givens rotations from the right
		do k = 1, n-1
			givens(1,:) = [ c(k), s(k)]  ! note this is transposed compared to above
			givens(2,:) = [-s(k), c(k)]
			a(1: k+1, k: k+1) = matmul(a(1: k+1, k: k+1), givens)
		end do

	end do
	!print *, "a = "
	!print "(4es15.5)", a

	! Don't sort the eigvals, because that will break the ordering of eigvecs
	!eigvals = sorted(diag(a))

	eigvals = diag(a)

	if (.not. present(eigvecs)) return
	allocate(eigvecs(n,n))

	!print *, "getting eigvecs via kernel ..."

	do i = 1, n
		eigval = eigvals(i)

		! Get eigenvector by finding the null-space of A - eigval * eye
		a = a0
		do j = 1, n
			a(j,j) = a(j,j) - eigval
		end do
		!print *, "a = "
		!print "(4es15.5)", a

		eigvec = lu_kernel(a)

		!********
		!! Find null-space using QR decomposition.  This also works
		!call qr_factor(a, diag_, iostat = io)
		!q = qr_get_q_expl(a, diag_)
		!!print *, "q = "
		!!print "(4es15.5)", q

		!! A - eigval*eye is singular, so the last row of Q will be in its null space
		!! and thus an eigenvector of A
		!!
		!! This probably won't work for eigenvalues with multiplicity.  In
		!! that case, you would need to get the last several rows and set
		!! multiple rows in the output
		!eigvec = q(:,n)
		!!print *, "eigvec = ", eigvec
		!********

		!! Confirm that it's an eigenvec.  All components of this print should be the
		!! same number
		!print *, "eigval = ", matmul(a0, eigvec) / eigvec
		!print *, "eigval = ", matmul(transpose(a0), eigvec) / eigvec

		eigvecs(:,i) = eigvec

	end do

end function eig_hess_qr_kernel

!===============================================================================

function polyfit_lu(x, y, n, iostat) result(p)
	! Fit a polynomial using LU decomposition.  The function polyfit() should be
	! used instead, which avoid unnecessary matmul's, using QR decomposition
	! instead
	!
	! Polynomial coefficients `p` are in ascending powers, unlike MATLAB's polyfit()
	use numa__utils
	double precision, intent(in) :: x(:), y(:)
	integer, intent(in) :: n
	integer, optional, intent(out) :: iostat

	double precision, allocatable :: p(:)
	!********

	character(len = :), allocatable :: msg
	double precision, allocatable :: xx(:,:), xtx(:,:)
	integer :: i, nx

	if (present(iostat)) iostat = 0

	nx = size(x)

	if (nx /= size(y)) then
		msg = "size(x) does not match size(y) in polyfit_lu()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if
	if (n+1 > nx) then
		msg = "polynomial degree is too high for size of data in polyfit_lu()"
		call PANIC(msg, present(iostat))
		iostat = 2
		return
	end if
	if (n < 0) then
		msg = "polynomial degree is negative in polyfit_lu()"
		call PANIC(msg, present(iostat))
		iostat = 3
		return
	end if

	allocate(xx(nx, n+1))
	xx(:,1) = 1
	do i = 2, n+1
		xx(:,i) = x * xx(:, i-1)
	end do

	xtx = matmul(transpose(xx), xx)
	p   = matmul(transpose(xx), y)

	call lu_invmul(xtx, p)
	!print *, "p = ", p
	!print *, "y = ", y

end function polyfit_lu

!===============================================================================

function polyfit(x, y, n, iostat) result(p)
	! Polynomial coefficients `p` are in ascending powers, unlike MATLAB's polyfit()
	use numa__utils
	double precision, intent(in) :: x(:), y(:)
	integer, intent(in) :: n
	integer, optional, intent(out) :: iostat

	double precision, allocatable :: p(:)
	!********

	character(len = :), allocatable :: msg
	double precision, allocatable :: xx(:,:)
	integer :: i, nx, io

	if (present(iostat)) iostat = 0

	nx = size(x)

	if (nx /= size(y)) then
		msg = "size(x) does not match size(y) in polyfit()"
		call PANIC(msg, present(iostat))
		iostat = 1
		return
	end if
	if (n+1 > nx) then
		msg = "polynomial degree is too high for size of data in polyfit()"
		call PANIC(msg, present(iostat))
		iostat = 2
		return
	end if
	if (n < 0) then
		msg = "polynomial degree is negative in polyfit()"
		call PANIC(msg, present(iostat))
		iostat = 3
		return
	end if

	allocate(xx(nx, n+1))
	xx(:,1) = 1
	do i = 2, n+1
		xx(:,i) = x * xx(:, i-1)
	end do
	!print *, "xx = "
	!!print "("//to_str(nx)//"es16.6)", xx
	!print "("//to_str(n+1)//"es16.6)", transpose(xx)

	p = qr_solve(xx, y, allow_rect = .true., iostat = io)
	if (io /= 0) then
		msg = "qr_solve() failed in polyfit()"
		call PANIC(msg, present(iostat))
		iostat = 4
		return
	end if

end function polyfit

!===============================================================================

function qr_solve_f64(a, b, allow_rect, iostat) result(x)
	! This can be a regular linear system solver, or with allow_rect, a
	! least-squares solver
	use numa__utils
	double precision, intent(inout) :: a(:,:)
	double precision, intent(in) :: b(:)
	logical, intent(in) :: allow_rect
	integer, optional, intent(out) :: iostat
	double precision, allocatable :: x(:)
	!********

	character(len = :), allocatable :: msg
	double precision, allocatable :: diag_(:)
	integer :: io

	if (present(iostat)) iostat = 0

	call qr_factor(a, diag_, allow_rect, io)
	if (io /= 0) then
		msg = "qr_factor() failed in qr_solve_f64()"
		call PANIC(msg, present(iostat))
		iostat = 4
		return
	end if
	!print *, "qr(a) = "
	!print "("//to_str(n+1)//"es16.6)", transpose(a)

	x = qr_mul_transpose(a, diag_, b)
	!print *, "qty = ", x
	call backsub(a, x)

end function qr_solve_f64

!===============================================================================

subroutine backsub_f64(a, bx, pivot)
	! Perform the back-substitution solve phase without pivoting.  This works as
	! a full solve if matrix `a` is upper (right) triangular
	double precision, intent(in) :: a(:,:)
	double precision, intent(inout) :: bx(:)
	integer, optional, intent(in) :: pivot(:)
	!********
	integer :: i, j, n

	n = min(size(a,1), size(a,2))
	if (present(pivot)) then

		do i = n, 1, -1
			do j = i+1, n
				bx    (pivot(i)) = &
					bx(pivot(i)) - &
					a (pivot(i), j) * &
					bx(pivot(j))
			end do
			bx    (pivot(i)) = &
				bx(pivot(i)) / &
				a (pivot(i), i)
		end do

	else

		do i = n, 1, -1
			do j = i+1, n
				bx(i) = bx(i) - a(i, j) * bx(j)
			end do
			bx(i) = bx(i) / a(i, i)
		end do

	end if
	!print *, "bx back = ", bx

end subroutine backsub_f64

!===============================================================================

subroutine backsub_c64(a, bx, pivot)
	! Perform the back-substitution solve phase without pivoting.  This works as
	! a full solve if matrix `a` is upper (right) triangular
	double complex, intent(in) :: a(:,:)
	double complex, intent(inout) :: bx(:)
	integer, optional, intent(in) :: pivot(:)
	!********
	integer :: i, j, n

	n = min(size(a,1), size(a,2))
	if (present(pivot)) then

		do i = n, 1, -1
			do j = i+1, n
				bx    (pivot(i)) = &
					bx(pivot(i)) - &
					a (pivot(i), j) * &
					bx(pivot(j))
			end do
			bx    (pivot(i)) = &
				bx(pivot(i)) / &
				a (pivot(i), i)
		end do

	else

		do i = n, 1, -1
			do j = i+1, n
				bx(i) = bx(i) - a(i, j) * bx(j)
			end do
			bx(i) = bx(i) / a(i, i)
		end do

	end if
	!print *, "bx back = ", bx

end subroutine backsub_c64

!===============================================================================

function polyval(p, x) result(y)
	double precision, intent(in) :: p(:), x(:)
	double precision, allocatable :: y(:)
	!********
	double precision, allocatable :: xpow(:)
	integer :: j, nx

	nx = size(x)
	allocate(y(nx))

	y = p(1)
	xpow = x
	do j = 2, size(p)
		y = y + p(j) * xpow
		xpow = xpow * x
	end do

end function polyval

!===============================================================================

function gauss_newton(x, y, f, df, beta0, iters, iostat) result(beta)
	! Use the Gauss-Newton algorithm to find parameters `beta` to fit a function
	! `f` to data `x` and `y` with an initial guess `beta0`.  The function has a
	! gradient `df` == df/dx
	!
	! This requires knowledge of the analytic derivative of f.  If the
	! derivative is not easily known, a derivative-free optimization algorithm
	! could be used instead like nelder_mead_fit()

	use numa__utils
	double precision, intent(in) :: x(:), y(:)
	procedure(fn_f64_params_to_f64) :: f
	procedure(fn_f64_params_to_vec_f64) :: df
	double precision, intent(in) :: beta0(:)
	integer, intent(in) :: iters
	integer, optional, intent(out) :: iostat

	double precision, allocatable :: beta(:)
	!********

	character(len = :), allocatable :: msg
	double precision, allocatable :: res(:), jac(:,:), delta(:)
	integer :: i, nx, nb, iter, io

	if (present(iostat)) iostat = 0

	nx = size(x)
	nb = size(beta0)
	allocate(res(nx))
	allocate(jac(nx, nb))

	beta = beta0
	do iter = 1, iters

		do i = 1, nx
			! Evaluate residual
			res(i) = y(i) - f(x(i), beta)
		end do
		!print *, "res = ", res

		do i = 1, nx
			! Evaluate Jacobian
			jac(i,:) = -df(x(i), beta)
		end do
		!print *, "jac = "
		!print "(2es16.6)", transpose(jac)

		delta = qr_solve(jac, res, allow_rect = .true., iostat = io)
		if (io /= 0) then
			msg = "qr_solve() failed in gauss_newton()"
			call PANIC(msg, present(iostat))
			iostat = 1
			return
		end if

		beta = beta - delta

	end do

end function gauss_newton

!===============================================================================

function nelder_mead_fit(x, y, f, beta0, beta_tol, iters) result(beta)
	! Fit data `x` and `y` by finding `beta` in order to minimize 
	! norm2(y - f(x, beta))
	!
	! This is 1D in terms of `x` and `y` for now, i.e. `f` takes a scalar `x`
	! and returns a scalar `y`, but it could probably be generalized to
	! multidimensional fns, and more easily so than gauss_newton().  The
	! parameters `beta` of course can have any size/dimension
	!
	! Maybe this should have an f_tol option instead of or in addition too
	! beta_tol

	use numa__utils
	double precision, intent(in) :: x(:), y(:)
	procedure(fn_f64_params_to_f64) :: f
	double precision, intent(in) :: beta0(:)
	double precision, optional, intent(in) :: beta_tol
	integer, optional, intent(in) :: iters

	double precision, allocatable :: beta(:)
	!********

	double precision :: fr, fe, fc, beta_tol_
	double precision, parameter :: alpha_ = 1, gamma_ = 2, rho_ = 0.5, sigma_ = 0.5
	double precision, allocatable :: bs(:,:), fs(:), bo(:), br(:), &
		be(:), bc(:)

	integer :: i, nx, nb, nb1, iter, iters_
	integer, allocatable :: idx(:)

	logical :: converged

	beta_tol_ = 1.d-3
	iters_ = 1000
	if (present(beta_tol)) beta_tol_ = beta_tol
	if (present(iters)) iters_ = iters

	nx = size(x)
	nb = size(beta0)
	nb1 = nb + 1  ! number of simplex points

	! Initial simplex
	allocate(bs(nb, nb1))
	do i = 1, nb
		bs(:,i) = beta0
		bs(i,i) = bs(i,i) + 1
	end do
	bs(:,nb1) = beta0

	! Evaluate fn on initial simplex
	allocate(fs(nb1))
	do i = 1, nb1
		fs(i) = nm_eval_res(bs(:,i))
	end do
	!print *, "fs init = ", fs

	converged = .false.
	do iter = 1, iters_

		! Sort
		call sortidx_f64_1(fs, idx)
		!print *, "idx = ", idx

		fs = fs(idx)
		bs = bs(:, idx)
		!print *, "fs = ", fs

		!print *, "bs = "
		!print "(2es16.6)", bs

		! Note: this is a bad criterion because 1 and nb1 may not be
		! representative of the simplex size
		if (norm2(bs(:,1) - bs(:,nb1)) < beta_tol_) then
			!print *, "iter = ", iter
			converged = .true.
			exit
		end if

		! Centroid
		bo = sum(bs(:, 1: nb), dim = 2) / nb
		!print *, "bo = ", bo

		! Reflect
		br = bo + alpha_ * (bo - bs(:,nb1))
		fr = nm_eval_res(br)

		if (fs(1) <= fr .and. fr < fs(nb)) then
			! Replace
			fs(nb1) = fr
			bs(:,nb1) = br
			cycle
		end if

		if (fr < fs(1)) then
			! Expand
			be = bo + gamma_ * (br - bo)
			fe = nm_eval_res(be)

			if (fe < fr) then
				fs(nb1) = fe
				bs(:,nb1) = be
			else
				fs(nb1) = fr
				bs(:,nb1) = br
			end if
			cycle
		end if

		if (fr < fs(nb1)) then
			! Contract outward
			bc = bo + rho_ * (br - bo)
			fc = nm_eval_res(bc)

			if (fc < fr) then
				fs(nb1) = fc
				bs(:,nb1) = bc
				cycle
			end if

		else
			! Contract inward
			bc = bo + rho_ * (bs(:,nb1) - bo)
			fc = nm_eval_res(bc)

			if (fc < fs(nb1)) then
				fs(nb1) = fc
				bs(:,nb1) = bc
				cycle
			end if

		end if

		! Shrink
		do i = 2, nb1
			bs(:,i) = bs(:,1) + sigma_ * (bs(:,i) - bs(:,1))
			fs(i) = nm_eval_res(bs(:,i))
		end do

	end do

	if (.not. converged) then
		write(*,*) YELLOW // "Warning" // COLOR_RESET // &
			": nelder_mead_fit() has not converged"
	end if
	beta = bs(:,1)

	!--------------------------------
	contains

		double precision function nm_eval_res(beta_) result(res)
			! Evaluate the residual and sum its squares
			double precision, intent(in) :: beta_(:)
			integer :: k
			res = 0
			do k = 1, nx
				res = res + (y(k) - f(x(k), beta_)) ** 2
			end do
		end function nm_eval_res

end function nelder_mead_fit

!===============================================================================

function nelder_mead(f, x0, x_tol, iters) result(x)
	! Solve an optimization problem by finding `x` in order to minimize 
	! f(x)

	use numa__utils
	procedure(fn_vec_f64_to_f64) :: f
	double precision, intent(in) :: x0(:)
	double precision, optional, intent(in) :: x_tol
	integer, optional, intent(in) :: iters

	double precision, allocatable :: x(:)
	!********

	double precision :: fr, fe, fc, x_tol_
	double precision, parameter :: alpha_ = 1, gamma_ = 2, rho_ = 0.5, sigma_ = 0.5
	double precision, allocatable :: xs(:,:), fs(:), xo(:), xr(:), &
		xe(:), xc(:)

	integer :: i, nb, nb1, iter, iters_
	integer, allocatable :: idx(:)

	logical :: converged

	x_tol_ = 1.d-3
	iters_ = 1000
	if (present(x_tol)) x_tol_ = x_tol
	if (present(iters)) iters_ = iters
	nb = size(x0)
	nb1 = nb + 1  ! number of simplex points

	! Initial simplex
	allocate(xs(nb, nb1))
	do i = 1, nb
		xs(:,i) = x0
		xs(i,i) = xs(i,i) + 1
	end do
	xs(:,nb1) = x0

	! Evaluate fn on initial simplex
	allocate(fs(nb1))
	do i = 1, nb1
		fs(i) = f(xs(:,i))
	end do
	!print *, "fs init = ", fs

	converged = .false.
	do iter = 1, iters_

		! Sort
		call sortidx_f64_1(fs, idx)
		!print *, "idx = ", idx

		fs = fs(idx)
		xs = xs(:, idx)
		!print *, "fs = ", fs

		!print *, "xs = "
		!print "(2es16.6)", xs

		! Note: this is a bad criterion because 1 and nb1 may not be
		! representative of the simplex size
		if (norm2(xs(:,1) - xs(:,nb1)) < x_tol_) then
			!print *, "iter = ", iter
			converged = .true.
			exit
		end if

		! Centroid
		xo = sum(xs(:, 1: nb), dim = 2) / nb
		!print *, "xo = ", xo

		! Reflect
		xr = xo + alpha_ * (xo - xs(:,nb1))
		fr = f(xr)

		if (fs(1) <= fr .and. fr < fs(nb)) then
			! Replace
			fs(nb1) = fr
			xs(:,nb1) = xr
			cycle
		end if

		if (fr < fs(1)) then
			! Expand
			xe = xo + gamma_ * (xr - xo)
			fe = f(xe)

			if (fe < fr) then
				fs(nb1) = fe
				xs(:,nb1) = xe
			else
				fs(nb1) = fr
				xs(:,nb1) = xr
			end if
			cycle
		end if

		if (fr < fs(nb1)) then
			! Contract outward
			xc = xo + rho_ * (xr - xo)
			fc = f(xc)

			if (fc < fr) then
				fs(nb1) = fc
				xs(:,nb1) = xc
				cycle
			end if

		else
			! Contract inward
			xc = xo + rho_ * (xs(:,nb1) - xo)
			fc = f(xc)

			if (fc < fs(nb1)) then
				fs(nb1) = fc
				xs(:,nb1) = xc
				cycle
			end if

		end if

		! Shrink
		do i = 2, nb1
			xs(:,i) = xs(:,1) + sigma_ * (xs(:,i) - xs(:,1))
			fs(i) = f(xs(:,i))
		end do

	end do

	if (.not. converged) then
		write(*,*) YELLOW // "Warning" // COLOR_RESET // &
			": nelder_mead() has not converged"
	end if
	x = xs(:,1)

end function nelder_mead

!===============================================================================

end module numa

